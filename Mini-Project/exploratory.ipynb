{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-Project - Covid-19 Cough Audio Classification\n",
    "\n",
    "1. Explore the dataset through code\n",
    "    * How many samples does the dataset contain?\n",
    "    * How many classes? How many samples per class? Show a histogram of the number of instances per class\n",
    "    * Play a random sample from each class\n",
    "    * Describe if/how you think the data distribution will affect training of a classifier.\n",
    "    * Decide what part of the dataset to use; all, some classes, some samples. Motivate your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load in metadata.csv\n",
    "data_path = r\"metadata_compiled.csv\"\n",
    "data = pd.read_csv(data_path, sep=\",\")\n",
    "#data.columns = data.columns.str.replace(\" \", \"\")\n",
    "\n",
    "data = data[[\"uuid\",\"cough_detected\",\"SNR\",\"age\",\"gender\",\"status\"]].loc[data['cough_detected'] >= 0.5].dropna()\n",
    "print(data[\"status\"].value_counts())\n",
    "print(\"Total samples\",len(data))\n",
    "\n",
    "data.to_csv(\"status_check.csv\")\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.title(\"Histogram of Patient Status\")\n",
    "plt.bar(data['status'].value_counts().index, data['status'].value_counts())\n",
    "plt.xticks(rotation=20, ha='right', fontsize=8)\n",
    "plt.xlabel('Class', fontsize=8)\n",
    "plt.ylabel('Frequency', fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data[\"uuid\"][1])\n",
    "\n",
    "data_dir_path = r\"../Dataset/\"\n",
    "# glob(os.path.join(clip_dir, '*.txt')):\n",
    "t = os.listdir(data_dir_path)\n",
    "\n",
    "\"\"\"\n",
    "#data = []\n",
    "#for i in t:\n",
    "#    if i.endswith(\".webm\") or i.endswith(\".ogg\"):\n",
    "#        data.append(os.path.join(data_dir_path, i))\n",
    "\n",
    "#data = pd.DataFrame(data, columns=[\"Links\"]).to_csv(\"files.csv\", index=False)  \n",
    "\n",
    "#print(t := os.path.join(data_dir_path, data[\"uuid\"][1]+\".json\"))\n",
    "\n",
    "#print(t[0])\n",
    "#print(data[\"uuid\"][1])\n",
    "\"\"\"\n",
    "\n",
    "webm_data = []\n",
    "ogg_data = []\n",
    "c = 0\n",
    "for file in data['uuid']:\n",
    "    if os.path.exists(os.path.join(data_dir_path, f'{file}.webm')):\n",
    "        webm_data.append(os.path.join(data_dir_path, f'{file}.webm'))\n",
    "    elif os.path.exists(os.path.join(data_dir_path, f'{file}.ogg')):\n",
    "        ogg_data.append(os.path.join(data_dir_path, f'{file}.ogg'))\n",
    "    #file_path = os.path.join(data_dir_path, f\"{path}.webm\")\n",
    "    #webm_data.append(file_path)\n",
    "    #json_data = pd.read_json(file_path, orient=\"table\")\n",
    "    #print(json_data)\n",
    "  \n",
    "webm_data = pd.DataFrame(webm_data)\n",
    "webm_data.to_csv(\"webm_data.csv\")\n",
    "ogg_data = pd.DataFrame(ogg_data)\n",
    "ogg_data.to_csv(\"ogg_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import torchaudio\n",
    "import torch\n",
    "\n",
    "class AudioDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir, data, label_encoder = None):\n",
    "        self.data_dir = data_dir\n",
    "        self.data = pd.read_csv(data, sep=\",\")\n",
    "        self.data = self.data[[\"uuid\",\"cough_detected\",\"SNR\",\"age\",\"gender\",\"status\"]].loc[self.data['cough_detected'] >= 0.5].dropna()\n",
    "        self.label_encoder = label_encoder\n",
    "        \n",
    "        self.data_paths = []\n",
    "        self.labels = []\n",
    "        for file in self.data['uuid']:\n",
    "            if os.path.exists(os.path.join(self.data_dir, f'{file}.webm')):\n",
    "                self.data_paths.append(os.path.join(self.data_dir, f'{file}.webm'))\n",
    "                self.labels.append(self.data.loc[self.data[\"uuid\"] == file, \"status\"].values[0])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        audio_path = self.data_paths[idx]\n",
    "        print(audio_path)\n",
    "        if os.path.exists(audio_path):\n",
    "            print(\"exists\")\n",
    "        audio_sample,_ = torchaudio.load(audio_path, format=\"FFmpeg\")\n",
    "        #audio_sample, fs = librosa.load(audio_path, sr=None)\n",
    "        #print(\"fs\",fs)\n",
    "        audio_label = self.labels[idx]\n",
    "        audio_label = self.label_encoder.transform(audio_label)\n",
    "        \n",
    "        return audio_sample, audio_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 32\u001b[0m\n\u001b[0;32m     26\u001b[0m data_dir_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../Dataset/MP3/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m#data = preprocess_data(data_path, data_dir_path)\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#print(data)\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m#print(pd.DataFrame(data))\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[0;32m     33\u001b[0m le \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[0;32m     34\u001b[0m le\u001b[38;5;241m.\u001b[39mfit([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhealthy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymptomatic\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCOVID-19\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32md:\\GitHub\\deep-learning-course\\.venv\\Lib\\site-packages\\sklearn\\__init__.py:87\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     84\u001b[0m         __check_build,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     85\u001b[0m         _distributor_init,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     86\u001b[0m     )\n\u001b[1;32m---> 87\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[0;32m     90\u001b[0m     __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     91\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     92\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    134\u001b[0m     ]\n",
      "File \u001b[1;32md:\\GitHub\\deep-learning-course\\.venv\\Lib\\site-packages\\sklearn\\base.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _IS_32BIT\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HTMLDocumentationLinkMixin, estimator_html_repr\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n",
      "File \u001b[1;32md:\\GitHub\\deep-learning-course\\.venv\\Lib\\site-packages\\sklearn\\utils\\__init__.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _joblib, metadata_routing\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bunch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Integral, Interval, validate_params\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclass_weight\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_class_weight, compute_sample_weight\n",
      "File \u001b[1;32md:\\GitHub\\deep-learning-course\\.venv\\Lib\\site-packages\\sklearn\\utils\\_estimator_html_repr.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstring\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Template\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__, config_context\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_version\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_IDCounter\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate sequential ids with a prefix.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32md:\\GitHub\\deep-learning-course\\.venv\\Lib\\site-packages\\sklearn\\utils\\fixes.py:17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mthreadpoolctl\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n",
      "File \u001b[1;32md:\\GitHub\\deep-learning-course\\.venv\\Lib\\site-packages\\scipy\\stats\\__init__.py:605\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m.. _statsrefmanual:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    600\u001b[0m \n\u001b[0;32m    601\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_warnings_errors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001b[0;32m    604\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[1;32m--> 605\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_variation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m variation\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32md:\\GitHub\\deep-learning-course\\.venv\\Lib\\site-packages\\scipy\\stats\\_stats_py.py:37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array, asarray, ma\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cdist\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mndimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _measurements\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (check_random_state, MapWrapper, _get_nan,\n\u001b[0;32m     40\u001b[0m                               rng_integers, _rename_parameter, _contains_nan,\n\u001b[0;32m     41\u001b[0m                               AxisError)\n",
      "File \u001b[1;32md:\\GitHub\\deep-learning-course\\.venv\\Lib\\site-packages\\scipy\\spatial\\__init__.py:116\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_plotutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_procrustes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m procrustes\n\u001b[1;32m--> 116\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_geometric_slerp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m geometric_slerp\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# Deprecated namespaces, to be removed in v2.0.0\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ckdtree, kdtree, qhull\n",
      "File \u001b[1;32md:\\GitHub\\deep-learning-course\\.venv\\Lib\\site-packages\\scipy\\spatial\\_geometric_slerp.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m euclidean\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnpt\u001b[39;00m\n",
      "File \u001b[1;32md:\\GitHub\\deep-learning-course\\.venv\\Lib\\site-packages\\scipy\\spatial\\distance.py:121\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _hausdorff\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m norm\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rel_entr\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _distance_pybind\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_copy_array_if_base_present\u001b[39m(a):\n",
      "File \u001b[1;32md:\\GitHub\\deep-learning-course\\.venv\\Lib\\site-packages\\scipy\\special\\__init__.py:777\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m    775\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sf_error\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SpecialFunctionWarning, SpecialFunctionError\n\u001b[1;32m--> 777\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _ufuncs\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ufuncs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;66;03m# Replace some function definitions from _ufuncs to add Array API support\u001b[39;00m\n",
      "File \u001b[1;32md:\\GitHub\\deep-learning-course\\.venv\\Lib\\site-packages\\scipy\\special\\_ufuncs.pyx:1\u001b[0m, in \u001b[0;36minit scipy.special._ufuncs\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:405\u001b[0m, in \u001b[0;36mparent\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def preprocess_data(data_path, data_dir_path):\n",
    "    # Read data file then remove every column other than the specified columns\n",
    "    # Removes empty samples and filters through cough probability\n",
    "    data = pd.read_csv(data_path, sep=\",\")\n",
    "    data = data[[\"uuid\",\"cough_detected\",\"SNR\",\"age\",\"gender\",\"status\"]].loc[data['cough_detected'] >= 0.5].dropna()\n",
    "    \n",
    "    webm_data = []\n",
    "    ogg_data = []\n",
    "    for file in data['uuid']:\n",
    "        if os.path.exists(os.path.join(data_dir_path, f'{file}.webm')):\n",
    "            #print(data.loc[data[\"uuid\"] == file, \"status\"].values[0])\n",
    "            label = data.loc[data[\"uuid\"] == file, \"status\"].values[0]\n",
    "            webm_data.append((os.path.join(data_dir_path, f'{file}.webm'), label))\n",
    "        elif os.path.exists(os.path.join(data_dir_path, f'{file}.ogg')):\n",
    "            ogg_data.append(os.path.join(data_dir_path, f'{file}.ogg'))\n",
    "    \n",
    "    return webm_data\n",
    "    \n",
    "data = r\"metadata_compiled.csv\"\n",
    "data_dir_path = r\"../Dataset/MP3/\"\n",
    "#data = preprocess_data(data_path, data_dir_path)\n",
    "\n",
    "#print(data)\n",
    "#print(pd.DataFrame(data))\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit([\"healthy\", \"symptomatic\", \"COVID-19\"])\n",
    "\n",
    "test = AudioDataset(data_dir_path, data, le)\n",
    "\n",
    "#print(test.__getitem__(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.__getitem__(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
