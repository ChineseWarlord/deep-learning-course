{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-10-09T20:28:04.534250Z","iopub.status.busy":"2023-10-09T20:28:04.533814Z","iopub.status.idle":"2023-10-09T20:28:10.933006Z","shell.execute_reply":"2023-10-09T20:28:10.931706Z","shell.execute_reply.started":"2023-10-09T20:28:04.534178Z"},"trusted":true},"outputs":[],"source":["# The Kaggle Python 3 environment comes with many helpful tools installed. \n","# See the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# If using another environment you may need to install the packages yourself\n","# e.g. pip install pytorch_lightning or !pip install pytorch_lightning\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import os, sys # filesystem operations\n","import matplotlib.pyplot as plt\n","import cv2\n","import random\n","import torch\n","from torch import nn\n","import torchvision.transforms as transforms\n","import pytorch_lightning as pl\n","from PIL import Image\n","from argparse import Namespace\n","\n","# When using Kaggle datasets upload of data is handled behind the scene\n","# Data files are available in the read-only \"../input/\" directory\n","# If you are using something else, you need to upload the data manually\n","# Here we take a look at the content of the input directory\n","input_dir = 'data/'\n","print(f\"input dir contains: {os.listdir(input_dir)}\")\n","dataset_dir = os.path.join(input_dir,'faces')\n","print(f\"dataset dir contains: {os.listdir(dataset_dir)}\")\n","train_dir = os.path.join(dataset_dir,'Train')\n","print(f\"train dir contains: {len(os.listdir(train_dir))} files such as {os.listdir(train_dir)[0]}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-09T20:28:10.936872Z","iopub.status.busy":"2023-10-09T20:28:10.935223Z","iopub.status.idle":"2023-10-09T20:28:11.011081Z","shell.execute_reply":"2023-10-09T20:28:11.009999Z","shell.execute_reply.started":"2023-10-09T20:28:10.936831Z"},"trusted":true},"outputs":[],"source":["import torch\n","import pytorch_lightning as pl\n","\n","device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","if torch.cuda.is_available():\n","    print(\"using {}\".format(torch.cuda.get_device_name(0)))\n","else:\n","    print(\"using CPU\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-09T20:28:11.013544Z","iopub.status.busy":"2023-10-09T20:28:11.012592Z","iopub.status.idle":"2023-10-09T20:28:11.648892Z","shell.execute_reply":"2023-10-09T20:28:11.647987Z","shell.execute_reply.started":"2023-10-09T20:28:11.013507Z"},"trusted":true},"outputs":[],"source":["# Lets see what is in 'train.csv'\n","train_df = pd.read_csv(os.path.join(dataset_dir,'train.csv'))\n","print(f'{train_df.head()}\\n')\n","\n","# Get an overview of the labels\n","labels = train_df['Class'].values\n","values, counts = np.unique(labels, return_counts=True) # count instances for each unique label\n","print(f'values {values}')\n","print(f'counts {counts}')\n","\n","# Inspect a couple of images\n","image_list = [os.path.join(train_dir,f) for f in train_df['ID'].values] # include the full path in the list\n","for _ in range(2):\n","    idx = random.randint(0,len(train_df))\n","    image = cv2.imread(image_list[idx])\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    print(f'Image {image_list[idx]} with shape {image.shape} and label {labels[idx]}')\n","    plt.imshow(image)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-09T20:28:11.652429Z","iopub.status.busy":"2023-10-09T20:28:11.651666Z","iopub.status.idle":"2023-10-09T20:28:11.682951Z","shell.execute_reply":"2023-10-09T20:28:11.681972Z","shell.execute_reply.started":"2023-10-09T20:28:11.652402Z"},"trusted":true},"outputs":[],"source":["import torch.nn.functional as F\n","\n","class AgeClassificationDataset(torch.utils.data.Dataset):\n","    def __init__(self, image_list, labels, transforms=None):\n","        # Make sure that image_list and labels are not unequal length\n","        if len(image_list) != len(labels):\n","            raise ValueError('image_list and labels are not equal length.')\n","        \n","        self.image_list = image_list\n","        self.labels = labels\n","        self.arranged_categories = ['YOUNG', 'MIDDLE', 'OLD']\n","        self.transforms = transforms\n","\n","    def load_sample(self, idx):\n","        img = Image.open(self.image_list[idx])\n","        label = torch.as_tensor(self.arranged_categories.index(self.labels[idx]), dtype=torch.int64) # convert categorical string label to int and the to one hot\n","        #label = F.one_hot(torch.as_tensor(self.arranged_categories.index(self.labels[idx]), dtype=torch.int64), num_classes=3) # convert categorical string label to int and the to one hot\n","        return img, label\n","\n","    def __getitem__(self, idx):\n","        img, target = self.load_sample(idx)\n","\n","        if self.transforms:\n","            img = self.transforms(img)\n","        else:\n","            convert_tensor = transforms.ToTensor()\n","            img = convert_tensor(img)\n","\n","        return img, target#torch.unsqueeze(target,0)\n","\n","    def __len__(self):\n","        return len(self.labels)\n","    \n","dataset = AgeClassificationDataset(image_list=image_list, labels=labels, transforms=None) \n","print(dataset[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-09T20:28:11.684936Z","iopub.status.busy":"2023-10-09T20:28:11.684561Z","iopub.status.idle":"2023-10-09T20:28:11.700514Z","shell.execute_reply":"2023-10-09T20:28:11.699639Z","shell.execute_reply.started":"2023-10-09T20:28:11.684900Z"},"trusted":true},"outputs":[],"source":["# from here: https://www.kaggle.com/code/ivankunyankin/resnet18-from-scratch-using-pytorch\n","class Block(nn.Module):\n","    \n","    def __init__(self, in_channels, out_channels, identity_downsample=None, stride=1):\n","        super(Block, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU()\n","        self.identity_downsample = identity_downsample\n","        \n","    def forward(self, x):\n","        identity = x\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.conv2(x)\n","        x = self.bn2(x)\n","        if self.identity_downsample is not None:\n","            identity = self.identity_downsample(identity)\n","        x += identity\n","        x = self.relu(x)\n","        return x\n","    \n","class ResNet18(nn.Module):\n","    \n","    def __init__(self, image_channels, num_classes):\n","        \n","        super(ResNet18, self).__init__()\n","        self.in_channels = 64\n","        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.relu = nn.ReLU()\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        \n","        #resnet layers\n","        self.layer1 = self.__make_layer(64, 64, stride=1)\n","        self.layer2 = self.__make_layer(64, 128, stride=2)\n","        self.layer3 = self.__make_layer(128, 256, stride=2)\n","        self.layer4 = self.__make_layer(256, 512, stride=2)\n","        \n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(512, num_classes)\n","        \n","    def __make_layer(self, in_channels, out_channels, stride):\n","        \n","        identity_downsample = None\n","        if stride != 1:\n","            identity_downsample = self.identity_downsample(in_channels, out_channels)\n","            \n","        return nn.Sequential(\n","            Block(in_channels, out_channels, identity_downsample=identity_downsample, stride=stride), \n","            Block(out_channels, out_channels)\n","        )\n","        \n","    def forward(self, x):\n","        \n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","        \n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        \n","        x = self.avgpool(x)\n","        x = x.view(x.shape[0], -1)\n","        x = self.fc(x)\n","        return x \n","    \n","    def identity_downsample(self, in_channels, out_channels):\n","        \n","        return nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1), \n","            nn.BatchNorm2d(out_channels)\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-09T20:28:11.702551Z","iopub.status.busy":"2023-10-09T20:28:11.702141Z","iopub.status.idle":"2023-10-09T20:28:11.717287Z","shell.execute_reply":"2023-10-09T20:28:11.716372Z","shell.execute_reply.started":"2023-10-09T20:28:11.702517Z"},"trusted":true},"outputs":[],"source":["# Here we define the model, optimizer, train and validation loop\n","class LightningClassifier(pl.LightningModule):\n","\n","    def __init__(self, hparams):\n","        super().__init__()\n","        self.save_hyperparameters()\n","        self.validation_step_outputs = []\n","\n","        self.lr = hparams.learning_rate\n","        self.model = ResNet18(image_channels=hparams.image_channels, num_classes=hparams.n_outputs)\n","        self.loss_function = nn.CrossEntropyLoss() #nn.BCEWithLogitsLoss()\n","        self.softmax = nn.Softmax(dim=1)\n","        from torchmetrics import Accuracy, Precision, Recall, F1Score, MetricCollection\n","        self.metric_collection = MetricCollection([F1Score(task='multiclass', num_classes=hparams.n_outputs, average='macro'), # https://torchmetrics.readthedocs.io/en/stable/classification/f1_score.html\n","                                                   Accuracy(task='multiclass', num_classes=hparams.n_outputs, average='macro'), # https://torchmetrics.readthedocs.io/en/stable/classification/accuracy.html\n","                                                  ])\n","        self.valid_metrics = self.metric_collection.clone(prefix='val_')\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","    def configure_optimizers(self):\n","        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n","        return optimizer\n","\n","    def training_step(self, batch, batch_idx):\n","        x, y = batch\n","        y_ = self.forward(x)\n","        loss = self.loss_function(y_, y)\n","        self.log('loss', loss, on_step=True)\n","        return {'loss': loss}\n","\n","    def validation_step(self, batch, batch_idx):\n","        x, y = batch\n","        y_ = self.forward(x)\n","        loss = self.loss_function(y_, y)\n","        self.validation_step_outputs.append(loss)\n","        scores = self.softmax(y_)\n","        metrics = self.valid_metrics(scores, y)\n","        self.log_dict(metrics)\n","        return {'loss': loss}\n","\n","    # Original validation function (does not work with the new version of lightning)\n","    #def on_validation_epoch_end(self, outputs):\n","    #    loss = torch.stack([x['loss'] for x in outputs]).mean()\n","    #    self.log('val_loss', loss, on_epoch=True, prog_bar=True)\n","    \n","    def on_validation_epoch_end(self):\n","        epoch_average = torch.stack(self.validation_step_outputs).mean()\n","        self.log(\"validation_epoch_average\", epoch_average)\n","        self.validation_step_outputs.clear()  # free memory\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-09T20:29:52.703705Z","iopub.status.busy":"2023-10-09T20:29:52.703363Z","iopub.status.idle":"2023-10-09T20:30:00.743736Z","shell.execute_reply":"2023-10-09T20:30:00.742547Z","shell.execute_reply.started":"2023-10-09T20:29:52.703676Z"},"trusted":true},"outputs":[],"source":["hparams = Namespace(**{# data\n","                       'exp_name': 'mp_age_classifier', # unique name for model and logs\n","                       'image_size': 224, # images size for input to model\n","                       'image_channels': 3, # 3 for RGB, 1 for grayscale images\n","                       # model\n","                       'arch': 'resnet18', # 'resnet18',\n","                       'n_outputs': 3, # number of dependent variables\n","                       # training\n","                       'wandb_api_key': '9be53a0c7076cae09612be80ee5e0e80d9dac79c',\n","                       'wandb_project': 'deep-learning-course',\n","                       'gpus': 1, # number of gpus\n","                       'max_epochs': 5, # number of times during training, where the whole dataset is traversed\n","                       'learning_rate': 1e-4, # generally, high means faster but worse convergence, low slow but better convergence\n","                       'batch_size': 4, # should be considered together with learning rate. decrease if using a small machine and getting memory errors\n","                       'n_workers': 0, # set to 0 in windows when working with a windows on a small machine\n","                       'persistent_workers': False\n","                       }\n","                    )\n","\n","model_name=f\"{hparams.exp_name}_{hparams.arch}_{hparams.image_size}x{hparams.image_channels}-{hparams.n_outputs}\"\n","print(\"Training model: {}\".format(model_name))\n","\n","# prepare output directories\n","if not os.path.exists('logs/'):\n","    os.mkdir('logs/')\n","output_dir = os.path.join('trained_models/',model_name)\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","os.environ[\"WANDB_API_KEY\"] = hparams.wandb_api_key\n","import wandb\n","wandb.init(config=vars(hparams))\n","from argparse import Namespace\n","hparams = Namespace(**wandb.config)\n","\n","from pytorch_lightning.loggers import WandbLogger\n","logger = WandbLogger(save_dir='wandb_logs/', offline=False, project=hparams.wandb_project, log_model=False)\n","\n","# The network needs the input to be a specific size and to pytorch tensors \n","train_transforms = transforms.Compose([transforms.Resize([hparams.image_size,hparams.image_size]),\n","                                       transforms.ToTensor()])\n","\n","train_val_set = AgeClassificationDataset(image_list=image_list, labels=labels, transforms=train_transforms) \n","\n","# since we only have the Train folder, we split its contents into training and validation set\n","proportions = [0.8, 0.2]\n","lengths = [int(p * len(train_val_set)) for p in proportions]\n","lengths[-1] = len(train_val_set) - sum(lengths[:-1])\n","train_set, val_set = torch.utils.data.random_split(train_val_set, lengths)\n","print(f\"train_val_set of len {len(train_val_set)} split into train_set {len(train_set)} and val_set {len(val_set)}\")\n","\n","from torch.utils.data import DataLoader\n","train_dataloader = DataLoader(train_set, batch_size=hparams.batch_size, shuffle=True, pin_memory=True, num_workers=hparams.n_workers)\n","val_dataloader = DataLoader(val_set, batch_size=hparams.batch_size, shuffle=False, pin_memory=True, num_workers=hparams.n_workers, persistent_workers=hparams.persistent_workers)\n","\n","# initialize model, training and validation code\n","lightning_module = LightningClassifier(hparams)\n","\n","# initialize training\n","from pytorch_lightning import Trainer\n","trainer = pl.Trainer(accelerator='gpu', \n","                     max_epochs=hparams.max_epochs,\n","                     logger=logger,\n","                     )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-09T20:30:15.788982Z","iopub.status.busy":"2023-10-09T20:30:15.788492Z","iopub.status.idle":"2023-10-09T20:36:34.016376Z","shell.execute_reply":"2023-10-09T20:36:34.015286Z","shell.execute_reply.started":"2023-10-09T20:30:15.788942Z"},"trusted":true},"outputs":[],"source":["# train model, takes a while\n","wandb.finish()\n","trainer.fit(lightning_module, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-09T20:41:37.797675Z","iopub.status.busy":"2023-10-09T20:41:37.797305Z","iopub.status.idle":"2023-10-09T20:45:21.638514Z","shell.execute_reply":"2023-10-09T20:45:21.637508Z","shell.execute_reply.started":"2023-10-09T20:41:37.797646Z"},"trusted":true},"outputs":[],"source":["# TODO: predict on gpu and in batches\n","predictor = lightning_module.model.eval().cpu()\n","test_set = val_set\n","\n","print(\"predicting 1 by 1 from test(val) set of size \", len(test_set))\n","labels, predictions = [], []\n","for i in range(len(test_set)):\n","    img, label = test_set[i]\n","    labels.append(label.numpy())\n","    with torch.no_grad():\n","        pred = predictor(torch.unsqueeze(img, 0))[0].cpu().numpy()\n","        predictions.append(np.argmax(pred))\n","    if i % 100 == 0:\n","        print(\"done with \", i)\n","    if i > 500: # stop after the first 500 to speed things up\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-09T20:46:49.805614Z","iopub.status.busy":"2023-10-09T20:46:49.805267Z","iopub.status.idle":"2023-10-09T20:46:50.030367Z","shell.execute_reply":"2023-10-09T20:46:50.029433Z","shell.execute_reply.started":"2023-10-09T20:46:49.805584Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","cm = confusion_matrix(labels, predictions, labels=[0,1,2])\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1,2])\n","disp.plot()\n","plt.gca().invert_yaxis()\n","plt.show()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":4}
